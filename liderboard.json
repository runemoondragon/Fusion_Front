[
    {
      "Name": "Claude 3.7 Sonnet",
      "Release Date": "2025-02-24",
      "Input Context": "200,000",
      "Output Context": "128,000",
      "GPQA": 0.848,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.75,
      "AIME 2024": 0.8
    },
    {
      "Name": "Grok-3 Mini",
      "Release Date": "2025-02-17",
      "Input Context": "128,000",
      "Output Context": "8,000",
      "GPQA": 0.846,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.958
    },
    {
      "Name": "Grok-3",
      "Release Date": "2025-02-17",
      "Input Context": "128,000",
      "Output Context": "8,000",
      "GPQA": 0.846,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.78,
      "AIME 2024": 0.93
    },
    {
      "Name": "Gemini 2.5 Pro",
      "Release Date": "2025-03-28",
      "Input Context": "1,048,576",
      "Output Context": "65,536",
      "GPQA": 0.84,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.817,
      "AIME 2024": 0.92
    },
    {
      "Name": "o3",
      "Release Date": "2025-04-16",
      "Input Context": "200,000",
      "Output Context": "100,000",
      "GPQA": 0.833,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.829,
      "AIME 2024": 0.916
    },
    {
      "Name": "o4-mini",
      "Release Date": "2025-04-16",
      "Input Context": "200,000",
      "Output Context": "100,000",
      "GPQA": 0.814,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.816,
      "AIME 2024": 0.934
    },
    {
      "Name": "o1-pro",
      "Release Date": "2024-12-17",
      "Input Context": "200,000",
      "Output Context": "100,000",
      "GPQA": 0.79,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.86
    },
    {
      "Name": "Gemini 2.5 Flash",
      "Release Date": "2025-04-17",
      "Input Context": "1,048,576",
      "Output Context": "65,536",
      "GPQA": 0.783,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.767,
      "AIME 2024": 0.88
    },
    {
      "Name": "o1",
      "Release Date": "2024-12-17",
      "Input Context": "200,000",
      "Output Context": "100,000",
      "GPQA": 0.78,
      "MMLU": 0.918,
      "MATH": 0.964,
      "HumanEval": 0.881,
      "MMLU-Pro": "null",
      "MMMU": 0.776,
      "AIME 2024": 0.743
    },
    {
      "Name": "o3-mini",
      "Release Date": "2025-01-30",
      "Input Context": "200,000",
      "Output Context": "100,000",
      "GPQA": 0.772,
      "MMLU": 0.869,
      "MATH": 0.979,
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.873
    },
    {
      "Name": "Llama 3.1 Nemotron Ultra 253B v1",
      "Release Date": "2025-04-07",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.76,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemini 2.0 Flash Thinking",
      "Release Date": "2025-01-21",
      "Input Context": "1,000,000",
      "Output Context": "65,536",
      "GPQA": 0.742,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.754,
      "AIME 2024": 0.733
    },
    {
      "Name": "DeepSeek R1 Zero",
      "Release Date": "2025-01-20",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.733,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.867
    },
    {
      "Name": "o1-preview",
      "Release Date": "2024-09-12",
      "Input Context": "128,000",
      "Output Context": "32,768",
      "GPQA": 0.733,
      "MMLU": 0.908,
      "MATH": 0.855,
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.42
    },
    {
      "Name": "DeepSeek-R1",
      "Release Date": "2025-01-20",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.715,
      "MMLU": 0.908,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.84,
      "MMMU": "null",
      "AIME 2024": 0.798
    },
    {
      "Name": "Llama 4 Maverick",
      "Release Date": "2025-04-05",
      "Input Context": "1,000,000",
      "Output Context": "1,000,000",
      "GPQA": 0.698,
      "MMLU": 0.855,
      "MATH": 0.612,
      "HumanEval": "null",
      "MMLU-Pro": 0.805,
      "MMMU": 0.734,
      "AIME 2024": "null"
    },
    {
      "Name": "GPT-4.5",
      "Release Date": "2025-02-27",
      "Input Context": "128,000",
      "Output Context": "4,096",
      "GPQA": 0.695,
      "MMLU": 0.908,
      "MATH": "null",
      "HumanEval": 0.88,
      "MMLU-Pro": "null",
      "MMMU": 0.752,
      "AIME 2024": 0.367
    },
    {
      "Name": "Phi 4 Reasoning Plus",
      "Release Date": "2025-04-30",
      "Input Context": "32,000",
      "Output Context": "32,000",
      "GPQA": 0.689,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.76,
      "MMMU": "null",
      "AIME 2024": 0.813
    },
    {
      "Name": "DeepSeek-V3 0324",
      "Release Date": "2025-03-25",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.684,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.812,
      "MMMU": "null",
      "AIME 2024": 0.594
    },
    {
      "Name": "Claude 3.5 Sonnet",
      "Release Date": "2024-10-22",
      "Input Context": "200,000",
      "Output Context": "200,000",
      "GPQA": 0.672,
      "MMLU": 0.904,
      "MATH": 0.783,
      "HumanEval": 0.937,
      "MMLU-Pro": 0.776,
      "MMMU": 0.683,
      "AIME 2024": "null"
    },
    {
      "Name": "Llama-3.3 Nemotron Super 49B v1",
      "Release Date": "2025-03-18",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.667,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "GPT-4.1",
      "Release Date": "2025-04-14",
      "Input Context": "1,047,576",
      "Output Context": "32,768",
      "GPQA": 0.663,
      "MMLU": 0.902,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.748,
      "AIME 2024": 0.481
    },
    {
      "Name": "Phi 4 Reasoning",
      "Release Date": "2025-04-30",
      "Input Context": "32,000",
      "Output Context": "32,000",
      "GPQA": 0.658,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.743,
      "MMMU": "null",
      "AIME 2024": 0.753
    },
    {
      "Name": "Qwen3 30B A3B",
      "Release Date": "2025-04-29",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.658,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.804
    },
    {
      "Name": "QwQ-32B",
      "Release Date": "2025-03-05",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": 0.652,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.795
    },
    {
      "Name": "QwQ-32B-Preview",
      "Release Date": "2024-11-28",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": 0.652,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.5
    },
    {
      "Name": "DeepSeek R1 Distill Llama 70B",
      "Release Date": "2025-01-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.652,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.867
    },
    {
      "Name": "GPT-4.1 mini",
      "Release Date": "2025-04-14",
      "Input Context": "1,047,576",
      "Output Context": "32,768",
      "GPQA": 0.65,
      "MMLU": 0.875,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.727,
      "AIME 2024": 0.496
    },
    {
      "Name": "Gemini 2.0 Flash",
      "Release Date": "2024-12-01",
      "Input Context": "1,048,576",
      "Output Context": "8,192",
      "GPQA": 0.621,
      "MMLU": "null",
      "MATH": 0.897,
      "HumanEval": "null",
      "MMLU-Pro": 0.764,
      "MMMU": 0.707,
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek R1 Distill Qwen 32B",
      "Release Date": "2025-01-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.621,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.833
    },
    {
      "Name": "o1-mini",
      "Release Date": "2024-09-12",
      "Input Context": "128,000",
      "Output Context": "65,536",
      "GPQA": 0.6,
      "MMLU": 0.852,
      "MATH": "null",
      "HumanEval": 0.924,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemini 1.5 Pro",
      "Release Date": "2024-05-01",
      "Input Context": "2,097,152",
      "Output Context": "8,192",
      "GPQA": 0.591,
      "MMLU": 0.859,
      "MATH": 0.865,
      "HumanEval": 0.841,
      "MMLU-Pro": 0.758,
      "MMMU": 0.659,
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek-V3",
      "Release Date": "2024-12-25",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.591,
      "MMLU": 0.885,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.759,
      "MMMU": "null",
      "AIME 2024": 0.392
    },
    {
      "Name": "DeepSeek R1 Distill Qwen 14B",
      "Release Date": "2025-01-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.591,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.8
    },
    {
      "Name": "Llama 4 Scout",
      "Release Date": "2025-04-05",
      "Input Context": "10,000,000",
      "Output Context": "10,000,000",
      "GPQA": 0.572,
      "MMLU": 0.796,
      "MATH": 0.503,
      "HumanEval": "null",
      "MMLU-Pro": 0.743,
      "MMMU": 0.694,
      "AIME 2024": "null"
    },
    {
      "Name": "Phi 4",
      "Release Date": "2024-12-12",
      "Input Context": "16,000",
      "Output Context": "16,000",
      "GPQA": 0.561,
      "MMLU": 0.848,
      "MATH": 0.804,
      "HumanEval": 0.826,
      "MMLU-Pro": 0.704,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Grok-2",
      "Release Date": "2024-08-13",
      "Input Context": "128,000",
      "Output Context": "8,000",
      "GPQA": 0.56,
      "MMLU": 0.875,
      "MATH": 0.761,
      "HumanEval": 0.884,
      "MMLU-Pro": 0.755,
      "MMMU": 0.661,
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.1 Nemotron Nano 8B V1",
      "Release Date": "2025-03-18",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.541,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Phi 4 Mini Reasoning",
      "Release Date": "2025-04-30",
      "Input Context": "128,000",
      "Output Context": "32,768",
      "GPQA": 0.52,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemini 2.0 Flash-Lite",
      "Release Date": "2025-02-05",
      "Input Context": "1,048,576",
      "Output Context": "8,192",
      "GPQA": 0.515,
      "MMLU": "null",
      "MATH": 0.868,
      "HumanEval": "null",
      "MMLU-Pro": 0.716,
      "MMMU": 0.68,
      "AIME 2024": "null"
    },
    {
      "Name": "Gemini 1.5 Flash",
      "Release Date": "2024-05-01",
      "Input Context": "1,048,576",
      "Output Context": "8,192",
      "GPQA": 0.51,
      "MMLU": 0.789,
      "MATH": 0.779,
      "HumanEval": 0.743,
      "MMLU-Pro": 0.673,
      "MMMU": 0.623,
      "AIME 2024": "null"
    },
    {
      "Name": "Grok-2 mini",
      "Release Date": "2024-08-13",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.51,
      "MMLU": 0.862,
      "MATH": 0.73,
      "HumanEval": 0.857,
      "MMLU-Pro": 0.72,
      "MMMU": 0.632,
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.1 405B Instruct",
      "Release Date": "2024-07-23",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.507,
      "MMLU": 0.873,
      "MATH": 0.738,
      "HumanEval": 0.89,
      "MMLU-Pro": 0.733,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.3 70B Instruct",
      "Release Date": "2024-12-06",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.505,
      "MMLU": 0.86,
      "MATH": 0.77,
      "HumanEval": 0.884,
      "MMLU-Pro": 0.689,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Claude 3 Opus",
      "Release Date": "2024-02-29",
      "Input Context": "200,000",
      "Output Context": "200,000",
      "GPQA": 0.504,
      "MMLU": 0.868,
      "MATH": 0.601,
      "HumanEval": 0.849,
      "MMLU-Pro": 0.685,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "GPT-4.1 nano",
      "Release Date": "2025-04-14",
      "Input Context": "1,047,576",
      "Output Context": "32,768",
      "GPQA": 0.503,
      "MMLU": 0.801,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.554,
      "AIME 2024": 0.294
    },
    {
      "Name": "Qwen2.5 32B Instruct",
      "Release Date": "2024-09-19",
      "Input Context": "131,072",
      "Output Context": "8,192",
      "GPQA": 0.495,
      "MMLU": 0.833,
      "MATH": 0.831,
      "HumanEval": 0.884,
      "MMLU-Pro": 0.69,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek R1 Distill Qwen 7B",
      "Release Date": "2025-01-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.491,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.833
    },
    {
      "Name": "Qwen2.5 72B Instruct",
      "Release Date": "2024-09-19",
      "Input Context": "131,072",
      "Output Context": "8,192",
      "GPQA": 0.49,
      "MMLU": "null",
      "MATH": 0.831,
      "HumanEval": 0.866,
      "MMLU-Pro": 0.711,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek R1 Distill Llama 8B",
      "Release Date": "2025-01-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.49,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.8
    },
    {
      "Name": "GPT-4 Turbo",
      "Release Date": "2024-04-09",
      "Input Context": "128,000",
      "Output Context": "4,096",
      "GPQA": 0.48,
      "MMLU": 0.865,
      "MATH": 0.726,
      "HumanEval": 0.871,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen3 235B A22B",
      "Release Date": "2025-04-29",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.475,
      "MMLU": 0.878,
      "MATH": 0.718,
      "HumanEval": "null",
      "MMLU-Pro": 0.682,
      "MMMU": "null",
      "AIME 2024": 0.857
    },
    {
      "Name": "Nova Pro",
      "Release Date": "2024-11-20",
      "Input Context": "300,000",
      "Output Context": "300,000",
      "GPQA": 0.469,
      "MMLU": 0.859,
      "MATH": 0.766,
      "HumanEval": 0.89,
      "MMLU-Pro": "null",
      "MMMU": 0.617,
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.2 90B Instruct",
      "Release Date": "2024-09-25",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.467,
      "MMLU": 0.86,
      "MATH": 0.68,
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.603,
      "AIME 2024": "null"
    },
    {
      "Name": "GPT-4o",
      "Release Date": "2024-08-06",
      "Input Context": "128,000",
      "Output Context": "16,384",
      "GPQA": 0.46,
      "MMLU": 0.857,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.747,
      "MMMU": 0.687,
      "AIME 2024": 0.131
    },
    {
      "Name": "Mistral Small 3.1 24B Instruct",
      "Release Date": "2025-03-17",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.46,
      "MMLU": 0.806,
      "MATH": 0.693,
      "HumanEval": 0.884,
      "MMLU-Pro": 0.668,
      "MMMU": 0.593,
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2.5 14B Instruct",
      "Release Date": "2024-09-19",
      "Input Context": "131,072",
      "Output Context": "8,192",
      "GPQA": 0.455,
      "MMLU": 0.797,
      "MATH": 0.8,
      "HumanEval": 0.835,
      "MMLU-Pro": 0.637,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Mistral Small 3 24B Instruct",
      "Release Date": "2025-01-30",
      "Input Context": "32,000",
      "Output Context": "32,000",
      "GPQA": 0.453,
      "MMLU": "null",
      "MATH": 0.706,
      "HumanEval": 0.848,
      "MMLU-Pro": 0.663,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemma 3 27B",
      "Release Date": "2025-03-12",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.424,
      "MMLU": "null",
      "MATH": 0.89,
      "HumanEval": 0.878,
      "MMLU-Pro": 0.675,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2 72B Instruct",
      "Release Date": "2024-07-23",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.424,
      "MMLU": 0.823,
      "MATH": 0.597,
      "HumanEval": 0.86,
      "MMLU-Pro": 0.644,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Nova Lite",
      "Release Date": "2024-11-20",
      "Input Context": "300,000",
      "Output Context": "2,048",
      "GPQA": 0.42,
      "MMLU": 0.805,
      "MATH": 0.733,
      "HumanEval": 0.854,
      "MMLU-Pro": "null",
      "MMMU": 0.562,
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.1 70B Instruct",
      "Release Date": "2024-07-23",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.417,
      "MMLU": 0.836,
      "MATH": "null",
      "HumanEval": 0.805,
      "MMLU-Pro": 0.664,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Claude 3.5 Haiku",
      "Release Date": "2024-10-22",
      "Input Context": "200,000",
      "Output Context": "200,000",
      "GPQA": 0.416,
      "MMLU": "null",
      "MATH": 0.694,
      "HumanEval": 0.881,
      "MMLU-Pro": 0.65,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemma 3 12B",
      "Release Date": "2025-03-12",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.409,
      "MMLU": "null",
      "MATH": 0.838,
      "HumanEval": 0.854,
      "MMLU-Pro": 0.606,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Claude 3 Sonnet",
      "Release Date": "2024-02-29",
      "Input Context": "200,000",
      "Output Context": "200,000",
      "GPQA": 0.404,
      "MMLU": 0.79,
      "MATH": 0.431,
      "HumanEval": 0.73,
      "MMLU-Pro": 0.568,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "GPT-4o mini",
      "Release Date": "2024-07-18",
      "Input Context": "128,000",
      "Output Context": "16,384",
      "GPQA": 0.402,
      "MMLU": 0.82,
      "MATH": 0.702,
      "HumanEval": 0.872,
      "MMLU-Pro": "null",
      "MMMU": 0.594,
      "AIME 2024": "null"
    },
    {
      "Name": "Nova Micro",
      "Release Date": "2024-11-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.4,
      "MMLU": 0.776,
      "MATH": 0.693,
      "HumanEval": 0.811,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemini 1.5 Flash 8B",
      "Release Date": "2024-03-15",
      "Input Context": "1,048,576",
      "Output Context": "8,192",
      "GPQA": 0.384,
      "MMLU": "null",
      "MATH": 0.587,
      "HumanEval": "null",
      "MMLU-Pro": 0.587,
      "MMMU": 0.537,
      "AIME 2024": "null"
    },
    {
      "Name": "Mistral Small 3.1 24B Base",
      "Release Date": "2025-03-17",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.375,
      "MMLU": 0.81,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.56,
      "MMMU": 0.593,
      "AIME 2024": "null"
    },
    {
      "Name": "Jamba 1.5 Large",
      "Release Date": "2024-08-22",
      "Input Context": "256,000",
      "Output Context": "256,000",
      "GPQA": 0.369,
      "MMLU": 0.812,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.535,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Phi-3.5-MoE-instruct",
      "Release Date": "2024-08-23",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.368,
      "MMLU": 0.789,
      "MATH": 0.595,
      "HumanEval": 0.707,
      "MMLU-Pro": 0.543,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2.5 7B Instruct",
      "Release Date": "2024-09-19",
      "Input Context": "131,072",
      "Output Context": "8,192",
      "GPQA": 0.364,
      "MMLU": "null",
      "MATH": 0.755,
      "HumanEval": 0.848,
      "MMLU-Pro": 0.563,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Grok-1.5",
      "Release Date": "2024-03-28",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.359,
      "MMLU": 0.813,
      "MATH": 0.506,
      "HumanEval": 0.741,
      "MMLU-Pro": 0.51,
      "MMMU": 0.536,
      "AIME 2024": "null"
    },
    {
      "Name": "GPT-4",
      "Release Date": "2023-06-13",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": 0.357,
      "MMLU": 0.864,
      "MATH": 0.42,
      "HumanEval": 0.67,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Mistral Small 3 24B Base",
      "Release Date": "2025-01-30",
      "Input Context": "32,000",
      "Output Context": "32,000",
      "GPQA": 0.344,
      "MMLU": 0.807,
      "MATH": 0.46,
      "HumanEval": "null",
      "MMLU-Pro": 0.544,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek R1 Distill Qwen 1.5B",
      "Release Date": "2025-01-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.338,
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.527
    },
    {
      "Name": "Claude 3 Haiku",
      "Release Date": "2024-03-13",
      "Input Context": "200,000",
      "Output Context": "200,000",
      "GPQA": 0.333,
      "MMLU": 0.752,
      "MATH": 0.389,
      "HumanEval": 0.759,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.2 11B Instruct",
      "Release Date": "2024-09-25",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.328,
      "MMLU": 0.73,
      "MATH": 0.519,
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.507,
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.2 3B Instruct",
      "Release Date": "2024-09-25",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.328,
      "MMLU": 0.634,
      "MATH": 0.48,
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Jamba 1.5 Mini",
      "Release Date": "2024-08-22",
      "Input Context": "256,144",
      "Output Context": "256,144",
      "GPQA": 0.323,
      "MMLU": 0.697,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": 0.425,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemma 3 4B",
      "Release Date": "2025-03-12",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.308,
      "MMLU": "null",
      "MATH": 0.756,
      "HumanEval": 0.713,
      "MMLU-Pro": 0.436,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2.5-Omni-7B",
      "Release Date": "2025-03-27",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": 0.308,
      "MMLU": "null",
      "MATH": 0.715,
      "HumanEval": 0.787,
      "MMLU-Pro": 0.47,
      "MMMU": 0.592,
      "AIME 2024": "null"
    },
    {
      "Name": "GPT-3.5 Turbo",
      "Release Date": "2023-03-21",
      "Input Context": "16,385",
      "Output Context": "4,096",
      "GPQA": 0.308,
      "MMLU": 0.698,
      "MATH": 0.431,
      "HumanEval": 0.68,
      "MMLU-Pro": "null",
      "MMMU": 0,
      "AIME 2024": "null"
    },
    {
      "Name": "Phi-3.5-mini-instruct",
      "Release Date": "2024-08-23",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.304,
      "MMLU": 0.69,
      "MATH": 0.485,
      "HumanEval": 0.628,
      "MMLU-Pro": 0.474,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Llama 3.1 8B Instruct",
      "Release Date": "2024-07-23",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.304,
      "MMLU": 0.694,
      "MATH": "null",
      "HumanEval": 0.726,
      "MMLU-Pro": 0.483,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemini 1.0 Pro",
      "Release Date": "2024-02-15",
      "Input Context": "32,760",
      "Output Context": "8,192",
      "GPQA": 0.279,
      "MMLU": 0.718,
      "MATH": 0.326,
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.479,
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2 7B Instruct",
      "Release Date": "2024-07-23",
      "Input Context": "131,072",
      "Output Context": "131,072",
      "GPQA": 0.253,
      "MMLU": 0.705,
      "MATH": 0.496,
      "HumanEval": "null",
      "MMLU-Pro": 0.441,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Phi 4 Mini",
      "Release Date": "2025-02-01",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": 0.252,
      "MMLU": 0.673,
      "MATH": 0.64,
      "HumanEval": "null",
      "MMLU-Pro": 0.528,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemma 3 1B",
      "Release Date": "2025-03-12",
      "Input Context": "32,000",
      "Output Context": "8,192",
      "GPQA": 0.192,
      "MMLU": "null",
      "MATH": 0.48,
      "HumanEval": 0.415,
      "MMLU-Pro": 0.147,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Command R+",
      "Release Date": "2024-08-30",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.757,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Kimi-k1.5",
      "Release Date": "2025-01-20",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.874,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.7,
      "AIME 2024": 0.775
    },
    {
      "Name": "Gemma 2 9B",
      "Release Date": "2024-06-27",
      "Input Context": "8,192",
      "Output Context": "8,192",
      "GPQA": "null",
      "MMLU": 0.713,
      "MATH": 0.366,
      "HumanEval": 0.402,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Gemma 2 27B",
      "Release Date": "2024-06-27",
      "Input Context": "8,192",
      "Output Context": "8,192",
      "GPQA": "null",
      "MMLU": 0.752,
      "MATH": 0.423,
      "HumanEval": 0.518,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Phi-3.5-vision-instruct",
      "Release Date": "2024-08-23",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.43,
      "AIME 2024": "null"
    },
    {
      "Name": "Phi-4-multimodal-instruct",
      "Release Date": "2025-02-01",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.551,
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2.5-Coder 32B Instruct",
      "Release Date": "2024-09-19",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.751,
      "MATH": 0.572,
      "HumanEval": 0.927,
      "MMLU-Pro": 0.504,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2.5-Coder 7B Instruct",
      "Release Date": "2024-09-19",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.676,
      "MATH": 0.466,
      "HumanEval": 0.884,
      "MMLU-Pro": 0.401,
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2-VL-72B-Instruct",
      "Release Date": "2024-08-29",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen3 32B",
      "Release Date": "2025-04-29",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.814
    },
    {
      "Name": "Qwen2.5 VL 7B Instruct",
      "Release Date": "2025-01-26",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.586,
      "AIME 2024": "null"
    },
    {
      "Name": "QvQ-72B-Preview",
      "Release Date": "2024-12-25",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.703,
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2.5 VL 72B Instruct",
      "Release Date": "2025-01-26",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.702,
      "AIME 2024": "null"
    },
    {
      "Name": "Qwen2.5 VL 32B Instruct",
      "Release Date": "2025-02-28",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": "null",
      "MMLU": 0.784,
      "MATH": 0.822,
      "HumanEval": 0.915,
      "MMLU-Pro": 0.688,
      "MMMU": 0.7,
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek VL2",
      "Release Date": "2024-12-13",
      "Input Context": "129,280",
      "Output Context": "129,280",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.511,
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek VL2 Tiny",
      "Release Date": "2024-12-13",
      "Input Context": "129,280",
      "Output Context": "129,280",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.407,
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek VL2 Small",
      "Release Date": "2024-12-13",
      "Input Context": "129,280",
      "Output Context": "129,280",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.48,
      "AIME 2024": "null"
    },
    {
      "Name": "DeepSeek-V2.5",
      "Release Date": "2024-05-08",
      "Input Context": "8,192",
      "Output Context": "8,192",
      "GPQA": "null",
      "MMLU": 0.804,
      "MATH": 0.747,
      "HumanEval": 0.89,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Grok-1.5V",
      "Release Date": "2024-04-12",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.536,
      "AIME 2024": "null"
    },
    {
      "Name": "IBM Granite 4.0 Tiny Preview",
      "Release Date": "2025-05-02",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.604,
      "MATH": "null",
      "HumanEval": 0.824,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Granite 3.3 8B Instruct",
      "Release Date": "2025-04-16",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.655,
      "MATH": "null",
      "HumanEval": 0.897,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.812
    },
    {
      "Name": "Granite 3.3 8B Base",
      "Release Date": "2025-04-16",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.639,
      "MATH": "null",
      "HumanEval": 0.897,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": 0.812
    },
    {
      "Name": "Llama 3.1 Nemotron 70B Instruct",
      "Release Date": "2024-10-01",
      "Input Context": "128,000",
      "Output Context": "4,000",
      "GPQA": "null",
      "MMLU": 0.802,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Mistral NeMo Instruct",
      "Release Date": "2024-07-18",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.68,
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Pixtral Large",
      "Release Date": "2024-11-18",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": 0.64,
      "AIME 2024": "null"
    },
    {
      "Name": "Ministral 8B Instruct",
      "Release Date": "2024-10-16",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.65,
      "MATH": 0.545,
      "HumanEval": 0.348,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Pixtral-12B",
      "Release Date": "2024-09-17",
      "Input Context": "128,000",
      "Output Context": "8,192",
      "GPQA": "null",
      "MMLU": 0.692,
      "MATH": 0.481,
      "HumanEval": 0.72,
      "MMLU-Pro": "null",
      "MMMU": 0.525,
      "AIME 2024": "null"
    },
    {
      "Name": "Codestral-22B",
      "Release Date": "2024-05-29",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": 0.811,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Mistral Small",
      "Release Date": "2024-09-17",
      "Input Context": "32,768",
      "Output Context": "32,768",
      "GPQA": "null",
      "MMLU": "null",
      "MATH": "null",
      "HumanEval": "null",
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    },
    {
      "Name": "Mistral Large 2",
      "Release Date": "2024-07-24",
      "Input Context": "128,000",
      "Output Context": "128,000",
      "GPQA": "null",
      "MMLU": 0.84,
      "MATH": "null",
      "HumanEval": 0.92,
      "MMLU-Pro": "null",
      "MMMU": "null",
      "AIME 2024": "null"
    }
  ]